{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Unsupervised machine learning with Scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons Licence\" style=\"width=50\" src=\"https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "Authors: \n",
    "Dr Antonia Mey -- antonia.mey@ed.ac.uk  \n",
    "Dr Matteo Degiacomi -- matteo.t.degiacomi@durham.ac.uk\n",
    "\n",
    "Content is partially adapted from the [Software Carpentries Machine learning lesson](https://carpentries-incubator.github.io/machine-learning-novice-sklearn/index.html)\n",
    " \n",
    "\n",
    "\n",
    "## Learning outcomes:\n",
    "### Questions\n",
    "How can we use clustering to find data points with similar attributes?\n",
    "### Objectives\n",
    "- Identify clusters in data using **k-means** clustering, **DB-scan** and **spectral clustering**. \n",
    "- See the limitations of k-means when clusters overlap.\n",
    "- Use spectral clustering to overcome the limitations of k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter cheat sheet**:\n",
    "- to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "nbgrader": {},
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Clustering is the grouping of data points which are similar to each other. It can be a powerful technique for identifying patterns in data. Clustering analysis does not usually require any training and is known as an unsupervised learning technique. The lack of a need for training means it can be applied quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Clustering\n",
    "\n",
    "- Looking for trends in data\n",
    "- Data compression, all data clustering around a point can be reduced to just that point. For example, reducing colour depth of an image.\n",
    "- Pattern recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "nbgrader": {},
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## K-means Clustering\n",
    "\n",
    "The K-means clustering algorithm is a simple clustering algorithm that tries to identify the centre of each cluster. It does this by searching for a point which minimises the distance between the centre and all the points in the cluster. The algorithm needs to be told how many clusters to look for, but a common technique is to try different numbers of clusters and combine it with other tests to decide on the best combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "nbgrader": {},
    "new_sheet": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## K-means with Scikit Learn\n",
    "\n",
    "To perform a k-means clustering with Scikit learn we first need to import the sklearn.cluster module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as skl_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create some random blobs using the make_blobs function. The n_samples argument sets how many points we want to use in all of our blobs. cluster_std sets the standard deviation of the points, the smaller this value the closer together they will be. centers sets how many clusters we’d like. random_state is the initial state of the random number generator, by specifying this we’ll get the same results every time we run the program. If we don’t specify a random state then we’ll get different points every time we run. This function returns two things, an array of data points and a list of which cluster each point belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "nbgrader": {},
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data, cluster_id = skl_datasets.make_blobs(n_samples=400, cluster_std=0.75, centers=4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some data we can go ahead and try to identify the clusters using K-means. First, we need to initialise the KMeans module and tell it how many clusters to look for. Next, we supply it some data via the fit function, in much the same we did with the regression functions earlier on. Finally, we run the predict function to find the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmean = skl_cluster.KMeans(n_clusters=4)\n",
    "Kmean.fit(data)\n",
    "clusters = Kmean.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can now be plotted to show all the points we randomly generated. To make it clearer which cluster points have been classified to we can set the colours (the c parameter) to use the clusters list that was returned by the predict function. The Kmeans algorithm also lets us know where it identified the centre of each cluster as. These are stored as a list called `cluster_centers_` inside the `Kmean` object. Let’s go ahead and plot the points from the clusters, colouring them by the output from the K-means algorithm, and also plot the centres of each cluster as a red X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(data[:, 0], data[:, 1], s=5, linewidth=0, c=clusters)\n",
    "for cluster_x, cluster_y in Kmean.cluster_centers_:\n",
    "    plt.scatter(cluster_x, cluster_y, s=100, c='r', marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as skl_cluster\n",
    "import sklearn.datasets as skl_datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data, cluster_id = skl_datasets.make_blobs(n_samples=400, cluster_std=0.75, centers=4, random_state=1)\n",
    "\n",
    "Kmean = skl_cluster.KMeans(n_clusters=4)\n",
    "Kmean.fit(data)\n",
    "clusters = Kmean.predict(data)\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], s=5, linewidth=0, c=clusters)\n",
    "for cluster_x, cluster_y in Kmean.cluster_centers_:\n",
    "    plt.scatter(cluster_x, cluster_y, s=100, c='r', marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "nbgrader": {},
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Working in multiple dimensions:</b>\n",
    "Although this example shows two dimensions the kmeans algorithm can work in more than two, it just becomes very difficult to show this visually once we get beyond 3 dimensions. Its very common in machine learning to be working with multiple variables and so our classifiers are working in multi-dimensional spaces.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# First task secion\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 1: Discuss: </b> </div>\n",
    "    What are the limitations and advantages of K-Means?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Solution: Suggested limitations and advantages</mark> </summary>\n",
    "\n",
    "Limitations:\n",
    "- Requires number of clusters to be known in advance\n",
    "- Struggles when clusters have irregular shapes\n",
    "- Will always produce an answer finding the required number of clusters even if the data isn’t clustered (or clustered in that many clusters).\n",
    "- Requires linear cluster boundaries\n",
    "\n",
    "Advantages:\n",
    "- Simple algorithm, fast to compute. A good choice as the first thing to try when attempting to cluster data.\n",
    "- Suitable for large datasets due to its low memory and computing requirements.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 2: K-means with overlapping clusters </b> </div>\n",
    "    Adjust the program above to increase the standard deviation of the blobs (the cluster_std parameter to make_blobs) and increase the number of samples (n_samples) to 4000. You should start to see the clusters overlapping. Do the clusters that are identified make sense? Is there any strange behaviour from this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Solution: Try it yourself</mark> </summary>\n",
    "\n",
    "```Python\n",
    "   a = b \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 3: How many clusters should we look for? </b> </div>\n",
    "Adjust the program above to increase the standard deviation of the blobs (the cluster_std parameter to make_blobs) and increase the number of samples (n_samples) to 4000. You should start to see the clusters overlapping. Do the clusters that are identified make sense? Is there any strange behaviour from this?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Solution: Try it yourself</mark> </summary>\n",
    "\n",
    "```Python\n",
    "   a = b \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## intro to DB scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use DB scan for ring dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spectral clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Introduce Alanine dipeptide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What happens when we cluster ADP with k-means, DB scan or spectral clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Key points:</b></div>   \n",
    "\n",
    "- Clustering is a form of unsupervised learning   \n",
    "- Unsupervised learning algorithms don’t need training   \n",
    "- Kmeans is a popular clustering algorithm.   \n",
    "- Kmeans struggles where one cluster exists within another, such as concentric circles.   \n",
    "- Spectral clustering is another technique which can overcome some of the limitations of Kmeans.    \n",
    "- Spectral clustering is much slower than Kmeans.    \n",
    "- As well as providing machine learning algorithms scikit learn also has functions to make example data   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Getting started with Python](Session_1.2.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
