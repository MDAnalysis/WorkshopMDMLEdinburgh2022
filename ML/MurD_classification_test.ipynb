{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06de947",
   "metadata": {},
   "source": [
    "# Machine Learning vs Molecular Dynamics Simulations\n",
    "\n",
    "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons Licence\" style=\"width=50\" src=\"https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "**Authors**: Dr Matteo Degiacomi (matteo.t.degiacomi@durham.ac.uk) and Dr Antonia Mey (antonia.mey@ed.ac.uk)\n",
    "\n",
    "**Learning Objectives**:\n",
    "* Using MDAnalysis to extract features from molecular dynamics simulations featuring different states\n",
    "* Using scikit-learn to classify conformations in different states according to the extracted features\n",
    "\n",
    "**Jupyter cheat sheet**:\n",
    "* to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "* to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196868f4",
   "metadata": {},
   "source": [
    "To get started with this tutorial, let's importing some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nglview as nv\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15ee17",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc18970",
   "metadata": {},
   "source": [
    "The simulations in this tutorial are presented in: [M.T. Degiacomi (2019). Coupling Molecular Dynamics and Deep Learning to Mine Protein Conformational Space, Structure](https://doi.org/10.1016/j.str.2019.03.018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906081c2",
   "metadata": {},
   "source": [
    "MurD is a 47-kDa ATP-driven ligase responsible for the biosynthesis of a bacterial peptidoglycan precursor (UDP-N-acetylmuramoyl-L-alanyl-D-glutamate). When bound to its ligand, UDP-N-acetylmuramoyl-L-alanyl-D-alanine, MurD is stabilized in a closed conformation (PDB: [3UAG](https://www.rcsb.org/structure/3UAG))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/MD_trajectories/\" # this is the path where the three simulations are located\n",
    "#folder = \"C:\\\\temp\\\\Dropbox\\\\MD_trajectories\\\\\" # this is the path where the three simulations are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ac822",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_closed = mda.Universe(f'{folder}MurD_closed.pdb')\n",
    "w = nv.show_mdanalysis(universe_closed)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09532026",
   "metadata": {},
   "source": [
    "In the absence of UDP-N-acetylmuramoyl-L-alanyl-D-alanine, MurD takes instead an open conformation (PDB: [1E0D](https://www.rcsb.org/structure/1E0D))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6223a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_open = mda.Universe(f'{folder}MurD_open.pdb')\n",
    "w = nv.show_mdanalysis(universe_open)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b5493",
   "metadata": {},
   "source": [
    "By taking the closed conformation and manually removing the ligand, the protein switches to an open conformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_closed_apo = mda.Universe(f'{folder}MurD_closed_apo.pdb')\n",
    "w = nv.show_mdanalysis(universe_closed_apo)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b28ab0",
   "metadata": {},
   "source": [
    "Our objective in this exercises is to assign the conformations of the latter simulation to either the closed or the open state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70575c8d",
   "metadata": {},
   "source": [
    "## 2. Setup of feature extraction tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965f351",
   "metadata": {},
   "source": [
    "The class `Featurizer` implements different ways of extracting features from a simulation using MDAnalysis. It is implemented to ensure consistency in feature extraction across the different datasets in the remainder of this exercises. Run this cell as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDAnalysis.analysis.dihedrals import Ramachandran\n",
    "from MDAnalysis.analysis import distances\n",
    "\n",
    "class Featurizer(object):\n",
    "    \n",
    "    def __init__(self, feature):\n",
    "        '''Featurizer class for extracting MD features with MDAnalysis\n",
    "        Parameters:\n",
    "        -----------\n",
    "        feature : String\n",
    "            name of feature\n",
    "        '''\n",
    "        if feature == \"ramachandran\":\n",
    "            self.get_features = self._get_features_ramachandran\n",
    "        elif feature == \"distance matrix\":    \n",
    "            self.get_features = self._get_features_distance_matrix\n",
    "        elif feature == \"coordinates\":    \n",
    "            self.get_features = self._get_features_coordinates\n",
    "        elif feature == \"custom\":\n",
    "            self.get_features = self._get_features_custom\n",
    "        else:\n",
    "            raise Exception(\"Features extraction method %s not recognised\"%feature)\n",
    "            \n",
    "        self.feature = feature\n",
    " \n",
    "    \n",
    "    def _get_features_coordinates(self, universe):\n",
    "        '''\n",
    "        alpha carbons coordinates\n",
    "        '''\n",
    "        crds = []\n",
    "        ca = universe.select_atoms(\"name CA\")\n",
    "        for ts in universe.trajectory:\n",
    "            crds.append(ca.positions.flatten())\n",
    "\n",
    "        return np.array(crds)\n",
    "\n",
    "\n",
    "    def _get_features_ramachandran(self, universe):\n",
    "        '''\n",
    "        dihedral angles\n",
    "        '''\n",
    "        r = Ramachandran(universe.select_atoms('protein')).run()\n",
    "        r_sin = np.sin(np.deg2rad(r.angles))\n",
    "        r_cos = np.cos(np.deg2rad(r.angles))\n",
    "        \n",
    "        r_sin = r_sin.reshape((r_sin.shape[0], np.prod(r_sin.shape[1:])))\n",
    "        r_cos = r_cos.reshape((r_cos.shape[0], np.prod(r_cos.shape[1:])))\n",
    "        return np.concatenate((r_sin, r_cos), axis=1)\n",
    "        \n",
    "    \n",
    "    def _get_features_distance_matrix(self, universe):\n",
    "        '''\n",
    "        returns the distance matrix of each conformation (lower diagonal, flattened)\n",
    "        see MDAnalysis.analysis.distances.self_distance_array\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def _get_features_custom(self, universe):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c5fdc",
   "metadata": {},
   "source": [
    "## 3. Preparation and analysis of training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa807ca7",
   "metadata": {},
   "source": [
    "We are now ready to collect features from two independent simulations of the closed and open state of MurD. Let's start by defining which kind of feature we are interested in extracting from the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = \"coordinates\"\n",
    "F = Featurizer(feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d91e4",
   "metadata": {},
   "source": [
    "We will now extract the features from the simulations of closed and open state. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from the simulations of the closed state\n",
    "feat_closed = F.get_features(universe_closed)\n",
    "print(f'closed state: {feat_closed.shape[0]} conformations, {feat_closed.shape[1]} features')\n",
    "\n",
    "# extract features from the simulation of the open state\n",
    "feat_open = F.get_features(universe_open)\n",
    "print(f'open state: {feat_open.shape[0]} conformations, {feat_open.shape[1]} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a36bf",
   "metadata": {},
   "source": [
    "Let's now convert the features we just extracted in datasets ready for classification. The datasets are combined and randomly split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_features = np.concatenate((feat_closed, feat_open))\n",
    "all_classes = np.concatenate((np.zeros(len(feat_closed)), np.ones(len(feat_open)))) #two numbered classes, 0: closed, 1: open.\n",
    "                      \n",
    "train_set, test_set, train_class, test_class = train_test_split(all_features, all_classes, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f28e66",
   "metadata": {},
   "source": [
    "Before going further, it is a good idea to take look at the training data we have just produced by projecting it on a lower dimensional space using Principal Components Analysis ([PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)), c.f. dimensionality reduction from yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(train_set)\n",
    "proj_closed = pca.transform(feat_closed)\n",
    "proj_open = pca.transform(feat_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e369a63",
   "metadata": {},
   "source": [
    "Now, let's plot a projection of the data in 2D space, also reporting the percentage of variance represented by each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ff0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(proj_closed[:, 0], proj_closed[:, 1], alpha=0.2, color=\"dodgerblue\", label=\"closed\")\n",
    "ax.scatter(proj_open[:, 0], proj_open[:, 1], alpha=0.2, color=\"red\", label=\"open\")\n",
    "ax.set_xlabel(f'PC 1, {pca.explained_variance_ratio_[0]*100:3.2f}%')\n",
    "ax.set_ylabel(f'PC 2, {pca.explained_variance_ratio_[1]*100:3.2f}%')\n",
    "ax.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afda96e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 1.</b> Discuss: Do PC1 and PC2 give you well-separated clusters? What does this tell us about the features we extracted? Do you need more dimensions to obtain a better separation?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1885a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 1</mark> </summary>\n",
    "If the open and closed state are well-separated in the 2D projection, this means that the features selected are highly correlated.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6e42f",
   "metadata": {},
   "source": [
    "## 4. Training a Random Forests classifier on input data <a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4da29",
   "metadata": {},
   "source": [
    "Let's start by training the a [Random Forests Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) using the training set we have just assembled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd04909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=10)\n",
    "RF.fit(train_set, train_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13646708",
   "metadata": {},
   "source": [
    "Let's now assess its performance against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RF.predict(test_set)\n",
    "success = np.sum((r-test_class)==0)\n",
    "percent = float(success)/len(test_class)*100\n",
    "print(f'Success of test set: {percent}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddcbcb",
   "metadata": {},
   "source": [
    "To see which features are deemed the most useful for a successful classification, we can observe their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dee97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = RF.feature_importances_\n",
    "importances_std = np.std([tree.feature_importances_ for tree in RF.estimators_], axis=0)\n",
    "\n",
    "if F.feature == \"coordinates\":\n",
    "\n",
    "    ca = universe_closed.select_atoms('name CA')[int(np.argmax(importances)/3)]\n",
    "    print(f'Most relevant amino acid: {ca.resname}{ca.resid}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04054770",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 2.</b> Run Section 4 again from the beginning. Is the most relevant feature always the same? Why?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6db5d8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 2</mark> </summary>\n",
    "Training the Random Forests classifier again will give different results because the training process is stochastic, and thus it will converge to different models. Their performance will be likely comparable, because there normally exist multiple models  performing equally comparatively well in a classification task.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164cfa0",
   "metadata": {},
   "source": [
    "## 5. Classification of conformations from new simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e6bc6",
   "metadata": {},
   "source": [
    "It is now time to characterize the simulation of a trajectory switching to the closed to the open state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_closed_apo = F.get_features(universe_closed_apo)\n",
    "r = RF.predict(feat_closed_apo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e85a3",
   "metadata": {},
   "source": [
    "Let's have a look at the classification. This can be done with a simple colorbar, where different colours represent different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(10, 1))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.pcolormesh([r])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"conformation / #\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec6c9a",
   "metadata": {},
   "source": [
    "Let's compare the three datasets (closed, open, and open apo) according to the value most important feature according to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc80a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(np.arange(len(feat_closed))/10., feat_closed[:, np.argmax(importances)], label=\"closed\", color=\"dodgerblue\")\n",
    "ax.plot(np.arange(len(feat_open))/10., feat_open[:, np.argmax(importances)], label=\"open\", color=\"orangered\")\n",
    "ax.plot(np.arange(len(feat_closed_apo))/10., feat_closed_apo[:, np.argmax(importances)], label=\"closed apo\", color=\"#682860\")\n",
    "\n",
    "ax.set_xlabel(\"time / ns\")\n",
    "ax.set_ylabel(\"distance / $\\AA$\")\n",
    "ax.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad9ea76",
   "metadata": {},
   "source": [
    "The closed apo simulation appears to take values in its most important feature different from anything seen in the training set. Here we will carry out an outlied detection using an Isolation Forest. More information about outlier detection is available [here](https://scikit-learn.org/stable/modules/outlier_detection.html). The following cell may take some time to run (a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(n_estimators=10, warm_start=True)\n",
    "clf.fit(train_set)\n",
    "\n",
    "y_closed_apo = clf.predict(feat_closed_apo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(10, 1))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.pcolormesh([y_closed_apo])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"conformation / #\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c88a4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 3.</b> There seem to be quite a few outliers, what does this tell us about the closed apo simulation?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c5f8d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 3</mark> </summary>\n",
    "The classification we obtained tells us that the second part of the simulation is more similar to the open than the closed state, however its conformations are not consistent with those sampled by the open simulations.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bba31f",
   "metadata": {},
   "source": [
    "Let's observe how the most relevant feature measured in the closed apo simulation relates to that of closed and open simulations in the eigenspace of the PCA projection. We will show the closed and open simulation in light gray, and the closed apo conformation with a colour gradient showing, from dark to light, the time evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e21383",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_closed_apo = pca.transform(feat_closed_apo)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(proj_closed[:, 0], proj_closed[:, 1], alpha=0.4, c=\"lightgrey\")\n",
    "ax.scatter(proj_open[:, 0], proj_open[:, 1], alpha=0.4, c=\"lightgrey\")\n",
    "ax.scatter(proj_closed_apo[:, 0], proj_closed_apo[:, 1], alpha=0.5, c=np.arange(len(proj_closed_apo))) \n",
    "ax.set_xlabel(f'PC 1, {pca.explained_variance_ratio_[0]*100:3.2f}%')\n",
    "ax.set_ylabel(f'PC 2, {pca.explained_variance_ratio_[1]*100:3.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0360c",
   "metadata": {},
   "source": [
    "A problem of using directly coordinates as a feature, is that results will depend on how the simulations are aligned: different alignments would lead to different results. If the trajectories were not aligned at all, using coordinates would not work because the signal would be dominated by the rototranslation of the whole protein as it randomly diffuses through the simulation box. For this reason, selecting features that are rototranslation invariant is advantageous. An example of such feature, is backbone dihedral angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98688b93",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 4.</b> In Section 2 we have defined the class <code>Featurizer</code>, defining different methods to extract features from an MDAnalysis Universe. The class was used in the first cell of Section 3. Run again this notebook from Section 3, setting  <code>feature_type = \"ramachandran\"</code>. What do you notice?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f4364",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 4</mark> </summary>\n",
    "Using the backbone dihedral angles seems to work according to the PCA, but classification fails to identify two states.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed673c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 5.1.</b> Return to Section 2 and, within the class <code>Featurizer</code>, use MDAnalysis to implement the method <code>_get_features_distance_matrix</code>, returning a flattened lower triangular distance matrix. Rerun the rest of the notebook with your new feature.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174fa8d1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 5.1.</mark> </summary>\n",
    "\n",
    "The following is the method to be implemented in Featurizer.\n",
    "    \n",
    "```Python    \n",
    "def _get_features_distance_matrix(self, universe):\n",
    "    '''\n",
    "    returns distance matrix of each conformation (lower diagonal, flattened)\n",
    "    '''\n",
    "    crds = []\n",
    "    ca = universe.select_atoms(\"name CA\")\n",
    "    for ts in universe.trajectory:\n",
    "        crds.append(distances.self_distance_array(ca.positions))\n",
    "\n",
    "    return np.array(crds)\n",
    "```\n",
    "\n",
    "    \n",
    "The following is a code snipped enabling the extraction of the most important feature (in Section 4).\n",
    "    \n",
    "```Python\n",
    "elif F.feature == \"distance matrix\": \n",
    "    \n",
    "    # get indices of most important CA atoms pair\n",
    "    na = len(universe_closed.select_atoms('name CA'))\n",
    "    pos = np.array(np.triu_indices(na))[:, np.argmax(importances)].T\n",
    "    \n",
    "    # retrieve their identity\n",
    "    ca1 = universe_closed.select_atoms('name CA')[pos[0]]\n",
    "    ca2 = universe_closed.select_atoms('name CA')[pos[1]]\n",
    "    print(f'Most relevant distance: {ca1.resname}{ca1.resid} - {ca2.resname}{ca2.resid}')\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6a153",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Answer 5.2.</b> If you are feeling adventurous, implement your own feature in the function <code>_get_features_custom</code></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1319981",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 5.2</mark> </summary>\n",
    "How about mesuring the angles formed by different domains? Or their relative orientation in spherical coordinates? Or selecting the distances between specific amino acid pairs, instead of using the whole distance matrix?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d3c4d",
   "metadata": {},
   "source": [
    "## 6. Extra material: hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74ae6d",
   "metadata": {},
   "source": [
    "In this tutorial, it was relatively easy to train a classifier able to separate the two classes: in all cases, the classification of the test set yielded high success rates. This may not always be the case though. In more difficult cases there are two things one could try to improve the success rate. The first, as explored in this tutorial, is identifying better features. The second, is **hyparameter tuning**.\n",
    "\n",
    "Any classifier is controlled by a series of parameters. In this tutorial we have defined one, the number of trees (`n_estimators`). This said, several other values could have been chosen for this parameter as well as others for which we used defaults (e.g. the maximal depth of each tree `max_depth`, or minimum number of samples a leaf can contain `min_samples_leaf`). \n",
    "\n",
    "Scikit-learn provides tools to train a classifier multiple times, with different sets of parameters, identifying the combination leading to best performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c54c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#define classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# define parameters and values to test\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100, 200],\n",
    "    'n_estimators': [10, 25, 30, 50, 100, 200]\n",
    "}\n",
    "\n",
    "# grid search over parameters space\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=params,\n",
    "                           cv = 4,\n",
    "                           n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "\n",
    "grid_search.fit(train_set, train_class)\n",
    "\n",
    "# best estimator found with grid search\n",
    "RF_best = grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
